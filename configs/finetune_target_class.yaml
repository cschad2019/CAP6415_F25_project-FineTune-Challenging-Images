# ──────────────────────────────────────────────────────────────────────────────
# Fine-tune config: focuses on the worst class from baseline ("bird").
# Stronger aug, class oversampling, mixup, cosine LR, EMA. CPU-friendly.
# ──────────────────────────────────────────────────────────────────────────────
seed: 42
project_name: "finetune_target"

dataset:
  name: "cifar10"
  data_dir: "./data"
  num_workers: 2

train:
  epochs: 8                 # short but effective on CPU
  batch_size: 128
  label_smoothing: 0.05
  freeze_backbone: false    # update the whole model
  mixup_alpha: 0.2          # 0 to disable
  grad_clip_norm: 1.0
  ema_decay: 0.995          # 0 to disable

optim:
  name: "adamw"
  lr: 0.0007
  weight_decay: 0.0005
  scheduler: "cosine"
  warmup_epochs: 1

target:
  focus_class: "bird"
  oversample: true
  oversample_factor: 8.0    # ↑ class exposure w/out changing labels

checkpoint:
  init: "results/best.pt"         # warm start from baseline
  best_path: "results/best_finetune.pt"

output:
  curves: "results/finetune_curves.png"
  cm: "results/finetune_confusion_matrix.png"
  samples_dir: "results/samples_finetune"
